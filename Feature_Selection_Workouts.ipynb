{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed23462-f93e-40b4-8c74-3667239c56fe",
   "metadata": {},
   "source": [
    "# Feature Selection Techniques\n",
    "\n",
    "###### Referrals : https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1173f6c2-63aa-4120-8e47-275a02901ae6",
   "metadata": {},
   "source": [
    "## 1. Supervised Feature Selection Techniques\n",
    "## 2. Unsupervised Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710a670-72e3-435f-9622-c08cc56a2e64",
   "metadata": {},
   "source": [
    "### Supervised Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142bdeba-df49-47a3-a01e-62fd9b295f1e",
   "metadata": {},
   "source": [
    "### 1. Filter methods\n",
    "### 2. Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e41c1-335c-4619-9e19-dd28401c15a1",
   "metadata": {},
   "source": [
    "#### Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2753f8a-d508-442d-9b3c-29658cedcae5",
   "metadata": {},
   "source": [
    "#### 1. Forward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d22dd8-00bf-4dee-89a8-ba6894fec93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Elimination starts with an empty set of features and iteratively combines features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a8179-0216-4bf3-8d4d-4b49a692b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with an empty set of selected features and initialize the best accuracy to 0.\n",
    "\n",
    "# In each iteration, we evaluate the contribution of each remaining feature to the model's accuracy.\n",
    "\n",
    "# The feature that leads to the highest accuracy improvement is added to the selected features set.\n",
    "\n",
    "# The loop continues until the desired number of features (num_features_to_select) is reached.\n",
    "\n",
    "# Finally, we print the selected features' indices and the best accuracy achieved during the forward selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde0618-6905-436d-9f1a-5d79a4d88ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an empty set of selected features\n",
    "selected_features = []\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Create a random forest classifier (you can use any classifier of your choice)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Number of features to select (you can set this based on your requirements)\n",
    "num_features_to_select = 3\n",
    "\n",
    "while len(selected_features) < num_features_to_select:\n",
    "    best_feature = None\n",
    "    best_feature_accuracy = 0.0\n",
    "\n",
    "    for feature_idx in range(X_train.shape[1]):\n",
    "        if feature_idx not in selected_features:\n",
    "            # Include the current feature in the selected features\n",
    "            current_features = selected_features + [feature_idx]\n",
    "\n",
    "            # Train the classifier on the current features\n",
    "            clf.fit(X_train[:, current_features], y_train)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            y_pred = clf.predict(X_test[:, current_features])\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Check if this feature selection leads to a better accuracy\n",
    "            if accuracy > best_feature_accuracy:\n",
    "                best_feature_accuracy = accuracy\n",
    "                best_feature = feature_idx\n",
    "\n",
    "    # Add the best feature to the selected features\n",
    "    selected_features.append(best_feature)\n",
    "\n",
    "    # Update the best accuracy achieved so far\n",
    "    if best_feature_accuracy > best_accuracy:\n",
    "        best_accuracy = best_feature_accuracy\n",
    "\n",
    "print(\"Selected Features (Indices):\", selected_features)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9346f62a-f2ea-4da8-ac4f-4c8c6759e1c7",
   "metadata": {},
   "source": [
    "##### Implementing using built in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57210731-d36c-4cad-85b3-a89b6c213eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (1.25.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (2.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (3.7.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\predator\\desktop\\jupyter_notebook\\new\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Predator\\Desktop\\Jupyter_Notebook\\new\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9530d313-d506-4c68-8b44-8d3bb98dfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sequential Forward Selection(sfs)\n",
    "sfs = SFS(LinearRegression(),\n",
    "          k_features=11,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring = 'r2',\n",
    "          cv = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65751ff9-200b-4721-b3ad-f721c0ed3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb29312-27e6-4223-a5bd-097ba4265ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes=load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c482a2-a2c6-4caa-89f7-a1d0da97a246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990749, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06833155, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286131, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04688253,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452873, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00422151,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
       " 'target_filename': 'diabetes_target.csv.gz',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ef0dd7-683f-41ab-baaa-bb9b96f4fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "diabetes_df=pd.DataFrame(diabetes.data,columns=diabetes.feature_names)\n",
    "diabetes_df[\"target\"]=diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a8287b-b56c-4f74-9758-55f700575d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e34b20a4-e0b8-4b44-bf32-87eadd3fe84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25300b3e-531c-45cc-9bf2-c8531d9445d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2073abaf-4915-4200-ae45-bf01b6709bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a95b10b1-356a-4772-85b4-bc908d214e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=diabetes_df.drop(\"target\",axis=1)\n",
    "y=diabetes_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2071136-d84d-4df2-ab34-f5f80355d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e060be44-86f1-44b1-af13-e7f06fbc4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d185cc8-373e-4a2e-8749-c39ef92bb7ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'k_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forward\u001b[38;5;241m=\u001b[39mSequentialFeatureSelector(\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mk_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mfloating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train,y_train))\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'k_features'"
     ]
    }
   ],
   "source": [
    "forward=SequentialFeatureSelector(RandomForestClassifier(n_jobs=1,\n",
    "                                                         k_features=1,\n",
    "                                                         forward=True,\n",
    "                                                         floating=False,\n",
    "                                                         verbose=2,\n",
    "                                                         scoring=\"accuracy\",\n",
    "                                                         cv=5).fit(X_train,y_train))\n",
    "                                            \n",
    "                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b19257-6a75-46e4-b6be-231ec996e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a35c15-6a45-4430-b44f-d1a14d79622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7875d9-2eaa-4817-b9a4-12117475e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5998abb2-9958-497c-8601-64a7179506db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer=load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732332ee-424c-49ad-88db-0a3885d8583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df=pd.DataFrame(cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99e2710-49a8-4330-b783-3c0c768cfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df[\"target\"]=cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a26cc8-bf82-4f7f-b06a-f27e8e1eef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0781f7f5-8b06-476b-9438-f8fe1600b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d54c447-e29d-49ca-a074-d9efe75f200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a03495-b6b6-468b-a55d-e9ba713da4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cancer_df.drop(\"target\",axis=1)\n",
    "y=cancer_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedab443-7c69-4d24-85a7-a974b6045d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=2,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90904cd-d447-49c7-89e4-9716afb1b57b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'k_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forward\u001b[38;5;241m=\u001b[39mSequentialFeatureSelector(\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mk_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mfloating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train,y_train))\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'k_features'"
     ]
    }
   ],
   "source": [
    "forward=SequentialFeatureSelector(RandomForestClassifier(n_jobs=1,\n",
    "                                                         =1,\n",
    "                                                         forward=True,\n",
    "                                                         floating=False,\n",
    "                                                         verbose=2,\n",
    "                                                         scoring=\"accuracy\",\n",
    "                                                         cv=5).fit(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53cc388-db95-4030-9713-1c40bd49e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Feature Indices: (0, 1, 23, 24, 27)\n",
      "Accuracy with Selected Features: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the SequentialFeatureSelector for forward selection\n",
    "num_features_to_select = 5  # You can set the desired number of features\n",
    "forward_selector = SequentialFeatureSelector(model, k_features=num_features_to_select, forward=True, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the forward selector to the training data\n",
    "forward_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = forward_selector.k_feature_idx_\n",
    "\n",
    "# Train a model using the selected features\n",
    "selected_features = X_train[:, selected_feature_indices]\n",
    "model.fit(selected_features, y_train)\n",
    "\n",
    "# Make predictions on the test set using the selected features\n",
    "X_test_selected = X_test[:, selected_feature_indices]\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Feature Indices:\", selected_feature_indices)\n",
    "print(\"Accuracy with Selected Features:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51f02c6-eb8d-40f9-b03f-a6911ad2ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871bbbe9-ee75-473f-a062-3d529e990a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcd8055-7fb9-483b-a354-d09bb14efc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cancer_df=pd.DataFrame(cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6395445e-175c-4103-9aaa-158549a9492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df[\"target\"]=cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013bcdaf-e6a0-4650-bea4-6bd3b0bc151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cancer_df.drop(\"target\",axis=1)\n",
    "y=cancer_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ba9ca6-18a2-4aa2-a6df-a18227d5fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23f201e-3dfa-44f9-b062-20bd413ffbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-09-30 11:38:40] Features: 1/4 -- score: 0.9208791208791209\n",
      "[2023-09-30 11:38:41] Features: 2/4 -- score: 0.9384615384615385\n",
      "[2023-09-30 11:38:41] Features: 3/4 -- score: 0.956043956043956C:\\Users\\Predator\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\n",
      "[2023-09-30 11:38:42] Features: 4/4 -- score: 0.9582417582417582"
     ]
    }
   ],
   "source": [
    "my_model=LogisticRegression()\n",
    "forward=SequentialFeatureSelector(my_model,k_features=4,forward=True,scoring=\"accuracy\",cv=5,verbose=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868cab25-b6a0-4f42-8999-5867c9495d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21, 25, 26)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_index = forward.k_feature_idx_\n",
    "selected_features_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96852aa9-c0c1-455d-9d8e-330dbf305cc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), (20, 21, 25, 26))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), (20, 21, 25, 26))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train a model using the selected features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m my_model\u001b[38;5;241m.\u001b[39mfit(selected_features, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set using the selected features\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), (20, 21, 25, 26))"
     ]
    }
   ],
   "source": [
    "# Train a model using the selected features\n",
    "selected_features = X_train[:, selected_features_index]\n",
    "my_model.fit(selected_features, y_train)\n",
    "\n",
    "# Make predictions on the test set using the selected features\n",
    "X_test_selected = X_test[:, selected_features_index]\n",
    "y_pred = my_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae44dd2-f079-435d-acd0-f6fe8846cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1dfa68-dc06-441c-96f0-8df1608519b8",
   "metadata": {},
   "source": [
    "#### 2. Backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a239583a-0c18-4108-84bd-ed33d4a8c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d96fab5-b13e-4e12-8122-3f754c65ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "514a08da-501f-4acf-9d50-d4fc0ac3ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mycancer.data\n",
    "y=mycancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2015bae3-17b1-4def-bda9-9891143136bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66efb901-ebdd-486b-9a95-17dc7b6168f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c843df03-e979-4593-a85e-365fa823809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-09-30 12:23:53] Features: 29/5 -- score: 0.9604395604395604\n",
      "[2023-09-30 12:25:22] Features: 28/5 -- score: 0.964835164835165\n",
      "[2023-09-30 12:26:51] Features: 27/5 -- score: 0.9648351648351647\n",
      "[2023-09-30 12:28:04] Features: 26/5 -- score: 0.9648351648351647\n",
      "[2023-09-30 12:28:35] Features: 25/5 -- score: 0.9648351648351647\n",
      "[2023-09-30 12:29:02] Features: 24/5 -- score: 0.9670329670329672\n",
      "[2023-09-30 12:29:28] Features: 23/5 -- score: 0.9670329670329669\n",
      "[2023-09-30 12:29:52] Features: 22/5 -- score: 0.9670329670329669\n",
      "[2023-09-30 12:30:15] Features: 21/5 -- score: 0.9736263736263737\n",
      "[2023-09-30 12:30:37] Features: 20/5 -- score: 0.9714285714285713\n",
      "[2023-09-30 12:30:58] Features: 19/5 -- score: 0.9736263736263737\n",
      "[2023-09-30 12:31:18] Features: 18/5 -- score: 0.9714285714285715\n",
      "[2023-09-30 12:31:36] Features: 17/5 -- score: 0.9714285714285713\n",
      "[2023-09-30 12:31:54] Features: 16/5 -- score: 0.9758241758241759\n",
      "[2023-09-30 12:32:09] Features: 15/5 -- score: 0.9758241758241759\n",
      "[2023-09-30 12:32:23] Features: 14/5 -- score: 0.9758241758241759\n",
      "[2023-09-30 12:32:36] Features: 13/5 -- score: 0.9758241758241759\n",
      "[2023-09-30 12:32:48] Features: 12/5 -- score: 0.9780219780219781\n",
      "[2023-09-30 12:32:59] Features: 11/5 -- score: 0.9780219780219781\n",
      "[2023-09-30 12:33:09] Features: 10/5 -- score: 0.9758241758241759\n",
      "[2023-09-30 12:33:18] Features: 9/5 -- score: 0.9780219780219781\n",
      "[2023-09-30 12:33:25] Features: 8/5 -- score: 0.9736263736263737\n",
      "[2023-09-30 12:33:32] Features: 7/5 -- score: 0.9692307692307693\n",
      "[2023-09-30 12:33:38] Features: 6/5 -- score: 0.9670329670329672\n",
      "[2023-09-30 12:33:43] Features: 5/5 -- score: 0.9670329670329672"
     ]
    }
   ],
   "source": [
    "backward_model=SequentialFeatureSelector(model,\n",
    "                                         k_features=5,\n",
    "                                         forward=False,\n",
    "                                         verbose=2,\n",
    "                                         cv=5,\n",
    "                                         scoring=\"accuracy\").fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cad733ea-ac4f-405d-8bd1-0323ee29a056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 23, 24, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=backward_model.k_feature_idx_\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b27ab610-762d-4a1f-880a-bd349bc55632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '8', '23', '24', '25')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_model.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900ef6b6-12aa-4698-a808-c03864f53b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using the selected features\n",
    "selected_features = X_train[:, indices]\n",
    "model.fit(selected_features, y_train)\n",
    "\n",
    "# Make predictions on the test set using the selected features\n",
    "X_test_selected = X_test[:, indices]\n",
    "y_pred = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0022fdec-b204-4a5b-bbf6-031583c19738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50ed49-5f6f-4ae2-b8db-087cc0d11895",
   "metadata": {},
   "source": [
    "#### 3. Bidirectional Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b8cbb3e-a5c0-4d2c-89f0-72ae7934f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-09-30 13:17:20] Features: 1/1 -- score: 0.887912087912088\n",
      "[2023-09-30 13:17:57] Features: 29/1 -- score: 0.9604395604395604\n",
      "[2023-09-30 13:18:32] Features: 28/1 -- score: 0.964835164835165\n",
      "[2023-09-30 13:19:05] Features: 27/1 -- score: 0.9648351648351647\n",
      "[2023-09-30 13:19:37] Features: 26/1 -- score: 0.9648351648351647\n",
      "[2023-09-30 13:20:08] Features: 25/1 -- score: 0.9648351648351647\n",
      "[2023-09-30 13:20:34] Features: 24/1 -- score: 0.9670329670329672\n",
      "[2023-09-30 13:21:00] Features: 23/1 -- score: 0.9670329670329669\n",
      "[2023-09-30 13:21:25] Features: 22/1 -- score: 0.9670329670329669\n",
      "[2023-09-30 13:21:49] Features: 21/1 -- score: 0.9736263736263737\n",
      "[2023-09-30 13:22:11] Features: 20/1 -- score: 0.9714285714285713\n",
      "[2023-09-30 13:22:32] Features: 19/1 -- score: 0.9736263736263737\n",
      "[2023-09-30 13:22:52] Features: 18/1 -- score: 0.9714285714285715\n",
      "[2023-09-30 13:23:10] Features: 17/1 -- score: 0.9714285714285713\n",
      "[2023-09-30 13:23:28] Features: 16/1 -- score: 0.9758241758241759\n",
      "[2023-09-30 13:23:42] Features: 15/1 -- score: 0.9758241758241759\n",
      "[2023-09-30 13:23:56] Features: 14/1 -- score: 0.9758241758241759\n",
      "[2023-09-30 13:24:09] Features: 13/1 -- score: 0.9758241758241759\n",
      "[2023-09-30 13:24:21] Features: 12/1 -- score: 0.9780219780219781\n",
      "[2023-09-30 13:24:32] Features: 11/1 -- score: 0.9780219780219781\n",
      "[2023-09-30 13:24:42] Features: 10/1 -- score: 0.9758241758241759\n",
      "[2023-09-30 13:24:50] Features: 9/1 -- score: 0.9780219780219781\n",
      "[2023-09-30 13:24:57] Features: 8/1 -- score: 0.9736263736263737\n",
      "[2023-09-30 13:25:04] Features: 7/1 -- score: 0.9692307692307693\n",
      "[2023-09-30 13:25:09] Features: 6/1 -- score: 0.9670329670329672\n",
      "[2023-09-30 13:25:14] Features: 5/1 -- score: 0.9670329670329672\n",
      "[2023-09-30 13:25:18] Features: 4/1 -- score: 0.9648351648351647\n",
      "[2023-09-30 13:25:21] Features: 3/1 -- score: 0.9692307692307693\n",
      "[2023-09-30 13:25:23] Features: 2/1 -- score: 0.9428571428571428\n",
      "[2023-09-30 13:25:24] Features: 1/1 -- score: 0.8747252747252748"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(455, 0)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Train a model using the selected features\u001b[39;00m\n\u001b[0;32m     40\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m X_train[:, selected_feature_indices]\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set using the selected features\u001b[39;00m\n\u001b[0;32m     44\u001b[0m X_test_selected \u001b[38;5;241m=\u001b[39m X_test[:, selected_feature_indices]\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\Desktop\\Jupyter_Notebook\\new\\Lib\\site-packages\\sklearn\\utils\\validation.py:978\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    982\u001b[0m         )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(455, 0)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the SequentialFeatureSelector for forward selection\n",
    "forward_selector = SequentialFeatureSelector(model, k_features=1, forward=True, verbose=2,scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the forward selector to the training data\n",
    "forward_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices from forward selection\n",
    "selected_feature_indices_forward = forward_selector.k_feature_idx_\n",
    "\n",
    "# Create the SequentialFeatureSelector for backward elimination\n",
    "backward_selector = SequentialFeatureSelector(model, k_features=1, forward=False, verbose=2,scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the backward selector to the training data\n",
    "backward_selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices from backward elimination\n",
    "selected_feature_indices_backward = backward_selector.k_feature_idx_\n",
    "\n",
    "# Combine the selected feature indices from both steps\n",
    "selected_feature_indices = list(set(selected_feature_indices_forward) & set(selected_feature_indices_backward))\n",
    "\n",
    "# Train a model using the selected features\n",
    "selected_features = X_train[:, selected_feature_indices]\n",
    "model.fit(selected_features, y_train)\n",
    "\n",
    "# Make predictions on the test set using the selected features\n",
    "X_test_selected = X_test[:, selected_feature_indices]\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Feature Indices:\", selected_feature_indices)\n",
    "print(\"Accuracy with Selected Features:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfdc6bb-62c4-4ed3-98ea-89eac4f6b758",
   "metadata": {},
   "source": [
    "#### 4. Exhaustive feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "626259cb-b398-499d-9903-1a6bdcc7cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6267be7-4fc8-4922-9fc7-95dc14478d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "can=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11e5184c-c6e1-4638-b368-715823608571",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=can.data\n",
    "y=can.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54e241ca-14f8-4b29-8e00-f5cc70c0bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "umodel=RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09f238ab-6c22-4d83-b773-895d49c03f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c94308-3c28-4e10-b0ce-56c4d435f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exhaustive=ExhaustiveFeatureSelector(umodel,\n",
    "                                     min_features=2,\n",
    "                                     max_features=5,\n",
    "                                     scoring=\"accuracy\",\n",
    "                                     cv=2).fit(X_train,y_train)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c88142-44cf-4bc0-b0e3-03b461c07206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
